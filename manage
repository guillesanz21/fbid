#! /usr/bin/env python3

import os
import sys
import argparse
import time

def main():
    parser = argparse.ArgumentParser(description="This script deploys a big data infrastructure whose purpose is to predict flight delays.")

    parser.add_argument("--up", help="Deploy the infrastructure. Options: docker, docker-compose|compose")

    parser.add_argument("--down", action="store_true", help="Brings down the services and removes the docker containers and docker images.")

    parser.add_argument("--pull", action="store_true", help="Pull all the needed base images from dockerhub")

    parser.add_argument("--download", action="store_true", help="Download the data (flights).")

    parser.add_argument("--train", action="store_true", help="Train the model with data")

    parser.add_argument("--package", action="store_true", help="Package the scala files")

    args = parser.parse_args()

    if not args.up and not args.down and not args.train \
        and not args.download and not args.pull and not args.package:
        parser.parse_args(["--help"])
        sys.exit(0)

    # print(args)

    data = not not (False or os.popen("ls data | grep simple_flight_delay*").read())
    packaged = not not (False or os.popen("ls docker/resources | grep   flight_prediction*.jar").read())
    trained = not not (False or os.popen("ls models | grep string_indexer_model*").read())
    sparkBuilded = not not (False or os.popen("docker images | grep fbid.spark").read())


    try:
        if args.down:
            down()
            return
        if args.download:
            download_data()
            download = True
            return
        if args.pull:
            pullImages()
            return
        if args.train:
            if data and sparkBuilded:
                train()
                trained = True
            return
        if args.package:
            packageScala()
            packaged = True
            return
        if args.up:
            if not pull:
                pullImages()
            if args.up == "docker":
                deploy_docker()
                return
            elif args.up in ["docker-compose", "compose"]:
                deploy_compose()
                return
            else:
                print("--up options: [docker, docker-compose|compose]")
                return
        else:
            parser.parse_args([--help])
        sys.exit(0)
    except:
        print("Error!")
        sys.exit(0)

def down():
    print("Stopping the containers:")
    c("docker stop kafka zoo mongo \
        && docker rm kafka zoo mongo spark \
        && docker rmi fbid.kafka fbid.zoo fbid.mongo fbid.spark")


    print("Deleting the custom network...")
    # c("docker network rm fbid")

    # TODO: Delete volumes (?)

def deploy_docker():
    down()

    print("\n\n########################")
    print("Deploying with docker...")
    print("########################\n")

    # print ("\n########## Creating the custom network...  ##########")
    # c("docker network create -d host fbid")


    print("\n########## Deploying zookeeper... ##########")
    c("docker build . -f docker/Dockerfile.zk -t fbid.zoo \
        && docker run --name zoo -d -p 2181:2181 --network host fbid.zoo")

    time.sleep(3)   # TODO: buscar otra manera de esperar a que el contenedor arranque y lance zookeeper

    print("\n########## Deploying kafka... ##########")
    c("docker build . -f docker/Dockerfile.kafka -t fbid.kafka \
        && docker run --name kafka -d -p 9092:9092 --network host fbid.kafka")
    
    time.sleep(3)

    createTopics = "/kafka/bin/kafka-topics.sh \
      --create \
      --bootstrap-server localhost:9092 \
      --replication-factor 1 \
      --partitions 1 \
      --topic flight_delay_classification_request"

    c(f"docker exec kafka {createTopics}")

    time.sleep(3)

    # c("docker exec kafka /kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list")

    print("\n########## Deploying MongoDB... ##########")
    c("docker build . -f docker/Dockerfile.mongo -t fbid.mongo \
        && docker run --name mongo -d -p 27017:27017 --network host \
        -v ${PWD}/data/mongo:/flights/db fbid.mongo")

    time.sleep(3)

    os.system("docker exec -it mongo ./import_distances.sh")

    print("\n########## Deploying Spark base image... ##########")
    os.system("docker build . -f docker/Dockerfile.spark -t fbid.spark")

    time.sleep(3)

    sparkBuilded = True
    if not trained:
        train()

    # MASTER
    c("docker run -p 7077:7077 -p 8080:8080 -e SPARK_MODE=master --network host \
        --name master bitnami/spark:3.1.2")
    # WORKER
    c("docker run --name worker -p 8081:8081 -e SPARK_MODE=worker \
        -e SPARK_MASTER_URL=spark://${USER}:7077 --network host bitnami/spark:3.1.2")
    #     # -e SPARK_MASTER_URL=localhost:7077 --network host bitnami/spark:3.1.2")

    # TODO: test
    c("docker build . -f docker/Dockerfile.spark-submit -t fbid.spark-submit \
        && docker run --name spark-submit -d --network host fbid.spark-submit")



def deploy_compose():
    print("Deploying with docker-compose...")
    # TODO

def pullImages():
    pull("alpine:3.13.6")
    pull("mongo:5.0.3")
    pull("openjdk:8-jdk")
    pull("hseeberger/scala-sbt:8u312_1.5.5_2.12.15")
    pull("bitnami/spark:3.1.2")

def pull(img):
    c(f"docker pull {img}")

def download_data():
    c("resources/download_data.sh")

def train():
    print("\n########## Deploying training container... ##########")
    c("docker build . -f docker/Dockerfile.spark -t fbid.spark")
    c("docker build . -f docker/Dockerfile.train -t fbid.train \
        && docker run --name train --network host \
        -v ${PWD}/models:/spark/models fbid.train")
    
    time.sleep(3)

def packageScala():
    c("docker run -it -v ${PWD}/flight_prediction:/flight_prediction \
        --rm hseeberger/scala-sbt:8u312_1.5.5_2.12.15 \
        bash -c 'cd /flight_prediction && sbt package'")
    c("cp flight_prediction/target/scala-2.12/flight_prediction_2.12-0.1.jar docker/resources/.")
    # c("rm -rf flight_prediction/target")

def c(cmd):
    os.system(cmd)

if __name__ == '__main__':
    main()